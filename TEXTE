https://epsagon.com/development/aws-lambda-programming-language-comparison/
https://aws.amazon.com/fr/blogs/compute/managing-aws-lambda-function-concurrency/#:~:text=In%20AWS%20Lambda%2C%20which%20is,happening%20at%20any%20given%20time.
https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html
https://docs.aws.amazon.com/lambda/latest/dg/invocation-sync.html

Réalisation Technique

Nous avons vu dans la partie précédente, la chaîne de production qui doit être réalisé. Pour la concrétiser, une multitude d'options s'offre à nous. Une des tâches de se stage à été de faire des choix, parmis tous les outils, et toute les méthodes possible celles qui serait la plus adéquats. Pour cela, il es important de bien avoir en tête ce que on désir.

Livrables :

Une solution de pipeline devra rescpeer les points suivants : 

     - Doit être parametrables, et ces paramètres doivent être accésibles sans avoir à modifier le code. 
     - Doit être sécurisé, les informations sensible (clef d'accès ect) ne doivent pas être accésible.
     - Doit être peu coûteuse.
     - Ne doit pas nécessiter d'intervention humaines, on cherche à construire une chaîne d'automatisaion, elle doit s'adater à tous les cas de figure possible
     
Dans l'idéal, on pourra également ajouter les livrables suivante : 

     - Le suivit du bon déroulement de la Pipeline doit être facilement lisible
     - Doit être facilement modifiable si lon veux adapter la solution pour d'autre type de produit
     
Présentation des différentes solutions : 

Dans cette section vont être présenter les différentes solutions qui ont été envisagé. Certaine de ces solutions ne concerne qu'un bout de la chaine, et sont parfois combinable.

PROPOSITION #1 : JENKINS

Jenkins est un outils de création de pipeline

PROPOSITION #2 : UTILISER LES OUTILS DE CREATION DE PIPELINE DE AWS

PROPOSITIONS #3 : OUTILS AWS 

Les propositions qui vont suivre permet contourner les outils de pipeline de AWS. Elle demande plus d'effort de programmation, mais on les préfrera pour leurs côut plus faible.
Tous ces outils sont tous de même des outils d'Amazone 

PROPOSITION #3 uno : STEP FUNCTION

AWS Step funcins est un services web qui permet de coordiner les différent composant d'une chaîne d'opération ("Qu'on appelle généralement workflow ou flux d'opéraions"). Cette outils permet de séparé simplement chaque opérations et de pouvoir visualiser et suivre se flux de manière graphique (cf figure). 
Le language pour programmer cete chîne est le "Amazon States Language", baser sur le JSON. Il permet d'executer toutes les opérations sur les services d'aws réalisable sur la console aws, ou par les sdk d'amazones. Ce services permet de facilité a transition entre les états mais ne réalise aucune execution. En revanche, il permet de manager des envionnement d'execution aws qui pourrons effectué du code, comme les lambdas.

Les avantage de cette outils t ça facilié de comprehenion t son suivit graphique qui le rend trs simple à débuger lorsqu'il  a des erreurs. Amazone facture ce services par le nombre de transition effectué à 0,025 USD, soit 0,022 Euro pour 1 000 transitions d'état. Ajouter à cela, le prix d'execution des Lambdas.

PROPOSITION #3 bis : CLOUD FORMATION

AWS Step funcins est un services web qui permet de coordiner les différent composant d'une chaîne d'opération ("Qu'on appelle généralement workflow ou flux d'opéraions"). Cette outils permet de séparé simplement chaque opérations et de pouvoir visualiser et suivre se flux de manière graphique (cf figure). 
Le language pour programmer cete chîne est le "Amazon States Language", baser sur le JSON. Il permet d'executer toutes les opérations sur les services d'aws réalisable sur la console aws, ou par les sdk d'amazones. Ce services permet de facilité a transition entre les états mais ne réalise aucune execution. En revanche, il permet de manager des envionnement d'execution aws qui pourrons effectué du code, comme les lambdas.

PROPOSITION #3 ters : Lambda et sdk

Il est possible de faire executer la pipeline uniquement par les lambdas. AWS fournis des sdk (libairie) qui contient des fonctions permetant d'effecuer toutes les opérations sur tous les services proposer par Amazone. Parmis les language de progamation disponible, le python à été choisi pour se prptotype, avec la librai developper par Amazone, Boto3.

Deux lambda on été utiliser pour cette pipeline de deploment. (cf. fig) La première Lambda va êter charger de récupéré le fichier 


DESCIPTION DE LA SOLUION DEINIIVE

La solution choisi est la popositin #3, celle qui code la pipeline en pthon, avec la sdk d'amazone et qui la fait eecute su des Lambda.

Pourquoi se choix ? 
Le choix de cette solution est motivé d'un part, par sa fleibilité, mais egalement pour son cout très faible comparé au autre soluion poposé. Enfin, l'atout de cette méthode comparativement  lutilisation de Jenkings par exemple est que l'on utilise quand même des outils Amazone, et les opération sont efectuer de manière interne au compte amazone de l'entreprise. En d'autre terme, on élimine la necessité de devoir se logger et donc de transmetre des identifiants ni en claire. Cette solutions propose le meilleurs compromis entre sécuité, fleibilité et cout.

Apreçu global : Lorsque les developpeurs publies une nouvelle version, il la push avec un outils de type git. S'en suit alors un script Jenking. C'est la chaîne d'intergration. Cette chaine va compilé et tester le code. A l'issue de cette chaine, la nouvelle verion du framework va être chargé dans le Bucket Source (cf fig). Ce fichier, c'est ceui indiquer sur le shema sous le nom de "Layer File". C'est la que la chîne de deployment commence .L'action de déposé un fichier dans le bucket va alors déclancher le script de la Pipeline sur une Lambda. Cette fonction que l'on nome "MainPipeline", va récupéré le fichier, publié la Layer, la tester, et ajouter les permissions on compte AWS qui doivent  avoir access. Toute ces opération sont effectuer dans la region par default (cannoniquement, en Virgini du Nord us-east-1). Puis avant de ce terminer, le scipt va déclancher de manire asyncrone (C'est à dire simultanément, comme des threads) N fonction lambda "Deployer". Chacune avec comme argument une regions différente. Leurs rôle, effectué le déployment de la layer dans la region qui leurs à été attitré. Elle vont donc à pari du bucket source, crée une copie de se bucket dans un bucket qui sera loalisé dans leurs régions, pour pouvoir publié le framework sous from d'une Layer dans leurs régions.

Exemplication complémentaire

Acess Control List.

OPIMISAIN DES PERFORMANCES : 

La chaîne présenter à la partie précédente démarre en série (de manière syncrone) une d'autres Lambdas effecuant la fonction "Depoyer". La fonction principal de la pipeline "ServerlessPipeline" va attendre qu'un deployer s'achève, soit qu'il récpère à réponse, pour démaré le deployer suivant. Hors, aws facture l'utilisation de la lambda selon sont temps d'utilisation. Il semble alors judicieux de réflechir à comment minimiser les temps d'attente. Pour évalué les performance de cette méthode d'organisation de l'execution des lambda, nous allons observé le temps moyens d'execution de la lambda en fonction du nombre de région dans laquelle on va la déployer. On cherchera à réduire au maximum cette durée afin de rendre notre solution plus economique.

Perormance lorsque les Deployer sont invoké de manière syncrone : 

- Durée de ServerlessPipeline seule (deployment seulement sur la régions par défault) :  ~7s

- Durée du Deployer seule (temps de déploiment pour 1 régions) :  ~14s

- Durée Théorique de Serverless Pipeline en fonction du nombre de régions : 7 + 14 * nb_regions

Vérification du modèle : Durée empirique de serverlessPipeline pour 2 région en plus de celle par default :  ~36s / 7 + 14*2 = 35s

Notre modèle n'est pas parfaitement exacte mais il sera satisfesant pour notre approximation. 

Soit est facturé durée de serverlessPipeline 35s (en comptant le temps d'attente) + durée des Deployer 14*2 = 28s  ==> durée facturé :  1min 3s

La première solution qui seble vidante pour résoudre se problème est de lancer les lambda "Deployer" de manière asyncrone (Soi en parralle) comme des Thread.


Perormance lorsque les Deployer sont invoké à partir d'un incrementeur : 

- Durée de ServerlessPipeline seule (deployment seulement sur la régions par défault) :  ~7s

- Durée du Deployer seule (temps de déploiment pour 1 régions) :  ~14s

- Durée Théorique de Serverless Pipeline en fonction du nombre de régions : 7 + 14 * nb_regions

Vérification du modèle : Durée empirique de serverlessPipeline pour 2 région en plus de celle par default :  ~36s / 7 + 14*2 = 35s

Notre modèle n'est pas parfaitement exacte mais il sera satisfesant pour notre approximation. 

Soit est facturé durée de serverlessPipeline 35s (en comptant le temps d'attente) + durée des Deployer 14*2 = 28s  ==> durée facturé :  1min 3s

DEINITION COLD START
When we invoke the Lambda for the first time, it downloads the code from S3, downloads all the dependencies, creates a container, and starts the application before it executes the code. This whole duration (except the execution of code) is known as the cold start time.


1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 
